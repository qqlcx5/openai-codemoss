const express = require('express');
const cors = require('cors');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 8002;

// å­˜å‚¨ä¼šè¯IDçš„å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§çŽ¯å¢ƒå»ºè®®ä½¿ç”¨Redisæˆ–æ•°æ®åº“ï¼‰
const conversationStore = new Map();

// ä¸­é—´ä»¶
app.use(cors());
app.use(express.json());

// TokenéªŒè¯ä¸­é—´ä»¶
const authenticateToken = (req, res, next) => {
  const authHeader = req.headers['authorization'];
  const token = authHeader && authHeader.split(' ')[1]; // Bearer TOKEN

  if (!token) {
    return res.status(401).json({
      error: {
        message: 'Missing authorization token',
        type: 'authentication_error',
        code: 'missing_token'
      }
    });
  }

  // è¿™é‡Œå¯ä»¥æ·»åŠ tokenéªŒè¯é€»è¾‘
  // ç›®å‰ç›´æŽ¥å°†tokenä¼ é€’ç»™mossæŽ¥å£
  req.mossToken = token;
  next();
};

// æ ¹æ®æ¨¡åž‹åç§°ç¡®å®šç‰ˆæœ¬å‚æ•°
const getVersionFromModel = (model) => {
  return model?.includes('-tmp') ? '2' : '1';
};

// åˆ›å»ºæ–°ä¼šè¯çš„å‡½æ•°
const createNewConversation = async (token, model) => {
  try {
    const fetch = (await import('node-fetch')).default;
    const response = await fetch('https://jiangsu.codemoss.vip/luomacode-api/conversation', {
      method: 'POST',
      headers: {
        'accept': 'application/json, text/plain, */*',
        'accept-language': 'zh-CN,zh;q=0.9',
        'cache-control': 'no-cache',
        'content-type': 'application/json',
        'pragma': 'no-cache',
        'priority': 'u=1, i',
        'sec-ch-ua': '"Chromium";v="140", "Not=A?Brand";v="24", "Google Chrome";v="140"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'empty',
        'sec-fetch-mode': 'cors',
        'sec-fetch-site': 'cross-site',
        'token': token
      },
      body: JSON.stringify({
        title: 'æ–°å»ºé—®é¢˜',
        assistantId: getVersionFromModel(model),
        version: '2'
      })
    });

    if (!response.ok) {
      throw new Error(`åˆ›å»ºä¼šè¯å¤±è´¥: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    if (data.code === 0 && data.list && data.list.length > 0) {
      return data.list[0].id;
    } else {
      throw new Error('åˆ›å»ºä¼šè¯è¿”å›žæ•°æ®æ ¼å¼é”™è¯¯');
    }
  } catch (error) {
    console.error('åˆ›å»ºæ–°ä¼šè¯æ—¶å‡ºé”™:', error);
    throw error;
  }
};

// æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®ä¼šè¯
const shouldResetConversation = (messages) => {
  if (!messages || messages.length === 0) return false;

  const lastUserMessage = messages
    .filter(msg => msg.role === 'user')
    .pop();

  if (!lastUserMessage) return false;

  const content = lastUserMessage.content.trim();
  return content === '1' || content === 'é‡ç½®';
};


// OpenAIæ ¼å¼åˆ°mossæ ¼å¼çš„è½¬æ¢å‡½æ•°
const convertToMossFormat = (openaiRequest, mossToken, conversationId) => {
  const { messages, model, temperature, max_tokens, stream } = openaiRequest;

  // æå–æœ€åŽä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºprompt
  const userMessages = messages.filter(msg => msg.role === 'user');
  const prompt = userMessages.length > 0 ? userMessages[userMessages.length - 1].content : '';

  // æ ¹æ®æ¨¡åž‹ç¡®å®šç‰ˆæœ¬
  const assistantId = getVersionFromModel(model);
  // å¦‚æžœæ¨¡åž‹æœ‰åŽ»é™¤ -tmp åŽç¼€
  const modelName = model.replace('-tmp', '');
  return {
    url: 'https://jiangsu.codemoss.vip/luomacode-api/v3/moss/completions',
    headers: {
      'accept': 'application/json, text/plain, */*',
      'accept-language': 'zh-CN,zh;q=0.9',
      'cache-control': 'no-cache',
      'content-type': 'application/json',
      'pragma': 'no-cache',
      'priority': 'u=1, i',
      'sec-ch-ua': '"Chromium";v="140", "Not=A?Brand";v="24", "Google Chrome";v="140"',
      'sec-ch-ua-mobile': '?0',
      'sec-ch-ua-platform': '"Windows"',
      'sec-fetch-dest': 'empty',
      'sec-fetch-mode': 'cors',
      'sec-fetch-site': 'cross-site',
      'token': mossToken
    },
    body: JSON.stringify({
      prompt: prompt,
      options: {
        openCot: false,
        appId: null,
        nonce: `hp_${Math.floor(Math.random() * 100000000)}`,
        conversationId: conversationId,
        openaiVersion: modelName || 'gpt-4o-mini',
        datasetIds: [],
        voice: false,
        image: false,
        assistantId: assistantId,
        version: '2'
      },
      apiKey: null
    })
  };
};

// mosså“åº”åˆ°OpenAIæ ¼å¼çš„è½¬æ¢å‡½æ•°
const convertToOpenAIFormat = (mossResponse, model = 'gpt-4o-mini') => {
  const timestamp = Math.floor(Date.now() / 1000);
  const id = `chatcmpl-${Math.random().toString(36).substr(2, 9)}`;

  return {
    id: id,
    object: 'chat.completion',
    created: timestamp,
    model: model,
    choices: [{
      index: 0,
      message: {
        role: 'assistant',
        content: mossResponse.content || mossResponse.text || mossResponse.response || ''
      },
      finish_reason: 'stop'
    }],
    usage: {
      prompt_tokens: mossResponse.usage?.prompt_tokens || 0,
      completion_tokens: mossResponse.usage?.completion_tokens || 0,
      total_tokens: mossResponse.usage?.total_tokens || 0
    }
  };
};

// æµå¼å“åº”è½¬æ¢å‡½æ•°
const convertToOpenAIStream = (chunk, model = 'gpt-4o-mini') => {
  const timestamp = Math.floor(Date.now() / 1000);
  const id = `chatcmpl-${Math.random().toString(36).substr(2, 9)}`;

  return {
    id: id,
    object: 'chat.completion.chunk',
    created: timestamp,
    model: model,
    choices: [{
      index: 0,
      delta: {
        content: chunk
      },
      finish_reason: null
    }]
  };
};

// ä¸»è¦çš„ä»£ç†ç«¯ç‚¹
app.post('/v1/chat/completions', authenticateToken, async (req, res) => {
  try {
    const { stream, messages } = req.body;
    const userKey = req.mossToken; // ä½¿ç”¨tokenä½œä¸ºç”¨æˆ·æ ‡è¯†

    let conversationId = conversationStore.get(userKey);

    // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®ä¼šè¯æˆ–åˆ›å»ºæ–°ä¼šè¯
    if (!conversationId || shouldResetConversation(messages)) {
      try {
        const newConversationId = await createNewConversation(req.mossToken, req.body.model);
        conversationStore.set(userKey, newConversationId);
        console.log(`æ–°ä¼šè¯å·²åˆ›å»ºï¼ŒID: ${newConversationId}`);

        return res.status(500).json({
          error: {
            message: 'é‡ç½®ä¼šè¯æˆ,è¯·é‡æ–°æé—®~~',
            type: 'conversation_error',
            code: 'create_conversation_failed'
          }
        });
      } catch (error) {
        console.error('åˆ›å»ºæ–°ä¼šè¯å¤±è´¥:', error);
        return res.status(500).json({
          error: {
            message: 'åˆ›å»ºä¼šè¯å¤±è´¥,è¯·é‡æ–°å‘é€è¯·æ±‚ 1 æˆ–è€… é‡ç½®',
            type: 'conversation_error',
            code: 'create_conversation_failed'
          }
        });
      }
    }

    const mossRequest = convertToMossFormat(req.body, req.mossToken, conversationId);
    console.log(`ä½¿ç”¨ä¼šè¯ID ${conversationId} å‘é€è¯·æ±‚åˆ° moss API...`);
    const fetch = (await import('node-fetch')).default;
    const response = await fetch(mossRequest.url, {
      method: 'POST',
      headers: mossRequest.headers,
      body: mossRequest.body
    });

    if (!response.ok) {
      throw new Error(`Moss API error: ${response.status} ${response.statusText}`);
    }

    if (stream) {
      // æµå¼å“åº”å¤„ç†
      res.writeHead(200, {
        'Content-Type': 'text/plain',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Headers': 'Cache-Control'
      });

      const reader = response.body;
      let buffer = '';
      reader.on('data', (chunk) => {
        buffer += chunk.toString();
        const lines = buffer.split('\n');
        buffer = lines.pop(); // ä¿ç•™æœ€åŽä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ

        for (const line of lines) {
          if (line.trim()) {
            try {
              // å¤„ç†mossæµå¼æ•°æ®å¹¶è½¬æ¢ä¸ºOpenAIæ ¼å¼
              const parsedChunk = JSON.parse(line)
              const aggregatedContent = parsedChunk?.msgItem?.theContent || ''
              const streamChunk = convertToOpenAIStream(aggregatedContent, req.body.model);
              res.write(`data: ${JSON.stringify(streamChunk)}\n\n`);
            } catch (e) {
              console.error('Error processing stream chunk:', e);
            }
          }
        }
      });

      reader.on('end', () => {
        res.write('data: [DONE]\n\n');
        res.end();
      });

      reader.on('error', (error) => {
        console.error('Stream error:', error);
        res.end();
      });

    } else {
      // éžæµå¼å“åº”å¤„ç†
      const mossData = await response.json();
      const openaiResponse = convertToOpenAIFormat(mossData, req.body.model);

      res.json(openaiResponse);
    }

  } catch (error) {
    console.error('Proxy error:', error);
    res.status(500).json({
      error: {
        message: error.message || 'Internal server error',
        type: 'server_error',
        code: 'proxy_error'
      }
    });
  }
});

// å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/health', (req, res) => {
  res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// èŽ·å–æ¨¡åž‹åˆ—è¡¨ç«¯ç‚¹ï¼ˆå…¼å®¹OpenAI APIï¼‰
app.get('/v1/models', (req, res) => {
  res.json({
    object: 'list',
    data: [
      {
        id: 'gpt-4o-mini',
        object: 'model',
        created: Math.floor(Date.now() / 1000),
        owned_by: 'moss-proxy'
      },
      {
        id: 'gpt-4o',
        object: 'model',
        created: Math.floor(Date.now() / 1000),
        owned_by: 'moss-proxy'
      },
      {
        id: 'gpt-4o-tmp',
        object: 'model',
        created: Math.floor(Date.now() / 1000),
        owned_by: 'moss-proxy'
      }
    ]
  });
});

app.listen(PORT, () => {
  console.log(`ðŸš€ Moss-OpenAI proxy server running on port ${PORT}`);
  console.log(`ðŸ“¡ Health check: http://localhost:${PORT}/health`);
  console.log(`ðŸ¤– Chat completions: http://localhost:${PORT}/v1/chat/completions`);
});

module.exports = app;
